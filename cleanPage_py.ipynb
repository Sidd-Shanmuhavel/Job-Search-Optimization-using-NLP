{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cleanPage.py",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPQbyGzSMdIAztRDBJCLWcG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sidd-Shanmuhavel/Job-Search-Optimization-using-NLP/blob/master/cleanPage_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2tCvvVTKNBQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "37681cbe-a32d-4fbb-fff2-bb7ce06f86fe"
      },
      "source": [
        "!pip install justext\n",
        "!pip install unidecode"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: justext in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
            "Requirement already satisfied: lxml>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from justext) (4.2.6)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-ofbhUNJyYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "import lxml\n",
        "import os\n",
        "import string\n",
        "import re\n",
        "\n",
        "import html\n",
        "import justext\n",
        "from unidecode import unidecode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLYPmWVLKxhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzEExSCqJ7zv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_html(page):\n",
        "    \"\"\" Clean HTML tags for webpages\n",
        "    \"\"\"\n",
        "    try:\n",
        "        parts = justext.justext(page, justext.get_stoplist('English'))\n",
        "    except lxml.etree.ParserError as e:\n",
        "        print('Page empty')\n",
        "        return ''\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(\"Can't decode utf-8\")\n",
        "        return ''\n",
        "    paragraphs = []\n",
        "    for part in parts:\n",
        "        if not part.is_boilerplate:\n",
        "            paragraphs.append(part.text)\n",
        "    return '\\n\\n'.join(paragraphs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dov0fHbmLAwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_non_alphanumeric(txt):\n",
        "    \"\"\" Remove all non-alphanumeric characters, except space, from the text\n",
        "    \"\"\"\n",
        "    return re.sub(r'[^a-zA-Z0-9 .]+', ' ', txt)\n",
        "\n",
        "\n",
        "def remove_non_alpha(txt):\n",
        "    \"\"\" Remove all non-alphabetical characters, except space, from the text\n",
        "    \"\"\"\n",
        "    return re.sub(r'[^a-zA-Z ]+', '', txt)\n",
        "\n",
        "\n",
        "def transliterate(txt):\n",
        "    \"\"\" Transliterate foreign characters into its Latin spelling.\n",
        "    For example, '\\u5317\\u4EB0' will be transliterated to 'Bei Jing'\n",
        "    \"\"\"\n",
        "    return unidecode(txt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svwLkw0iLEKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collapse_white_spaces(txt):\n",
        "    \"\"\"Collapse multiple white spaces into one white space\n",
        "    \"\"\"\n",
        "    clean_txt = ''\n",
        "    prev = None\n",
        "    for c in txt:\n",
        "        if c == ' ' and prev == ' ':\n",
        "            continue\n",
        "        else:\n",
        "            clean_txt += c\n",
        "        prev = c\n",
        "    return clean_txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2FX92lrLHWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def connect_lines(txt, line_sep='\\n'):\n",
        "    \"\"\" This happens when you crawl text from a webpage and\n",
        "    they have random breaking lines mid-sentence.\n",
        "    This function is to connect those lines.\n",
        "    Two consecutive lines are separated by line_sep.\n",
        "    \"\"\"\n",
        "    lines = txt.split('\\n')\n",
        "\n",
        "    result, curr = '', ''\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            if curr:\n",
        "                result += (curr + '\\n')\n",
        "            result += line_sep\n",
        "            curr = ''\n",
        "        else:\n",
        "            curr += (line + ' ')\n",
        "\n",
        "    return result + curr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4vOM8BpLJ-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_page(page):\n",
        "    try:\n",
        "        page = page.decode('utf-8')\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(\"Can't decode\", e)\n",
        "\n",
        "    page = page.strip()\n",
        "    if not page:\n",
        "        return ''\n",
        "    txt = parse_html(page)\n",
        "    txt = transliterate(txt)\n",
        "    txt = html.unescape(txt)\n",
        "    return txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr3lsnfaLMyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_unprintable(txt):\n",
        "    \"\"\"Find the list of unprintable character\n",
        "    and return a Counter of them\n",
        "    \"\"\"\n",
        "    printable = set(string.printable)\n",
        "    unprintable = [c for c in txt if c not in printable]\n",
        "    return Counter(unprintable)\n",
        "\n",
        "\n",
        "def replace_unprintable(txt):\n",
        "    \"\"\"Replace non-printable characters with printable characters\n",
        "    \"\"\"\n",
        "    printable = set(string.printable)\n",
        "    lines = open(f'{dir_path}/unprintable_chars.txt', 'r').readlines()\n",
        "    chars = {line.strip().split(':')[0]:\n",
        "             line.strip().split(':')[1] for line in lines}\n",
        "    return ''.join([c if c in printable else chars[c] for c in txt])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P88BW_4u3HMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_page(link, context=None, timeout=None):\n",
        "    \"\"\"\n",
        "    Return code, page\n",
        "    0: successfully read (write to index)\n",
        "    1: bad_url (write to bad_url)\n",
        "    2: unicode error (write to non_ascii_urls)\n",
        "    3. bad_connection_urls\n",
        "    When code is not 0, return ''\n",
        "    \"\"\"\n",
        "    try:\n",
        "        req = urllib.request.Request(link)\n",
        "    except ValueError as e:\n",
        "        print(link, \"doesn't exist.\")\n",
        "        return 1, ''\n",
        "    except ConnectionResetError as e:\n",
        "        print('ConnectionResetError', link)\n",
        "        return 3, ''\n",
        "\n",
        "    try:\n",
        "        if timeout is not None:\n",
        "            response = urllib.request.urlopen(\n",
        "                req, context=context, timeout=timeout)\n",
        "        else:\n",
        "            response = urllib.request.urlopen(req, context=context)\n",
        "    except UnicodeError as e:\n",
        "        print('UnicodeError for', link)\n",
        "        return 2, ''\n",
        "    except (urllib.error.HTTPError) as e:\n",
        "        print('Error {} for {}'.format(e.code, link))\n",
        "        return 1, ''\n",
        "    except urllib.error.URLError as e:\n",
        "        print('URLError for', link)\n",
        "        return 1, ''\n",
        "    except http.client.HTTPException as e:\n",
        "        print('HTTPException', link)\n",
        "        return 1, ''\n",
        "    except http.client.RemoteDisconnected as e:\n",
        "        print('RemoteDisconnected', link)\n",
        "        return 1, ''\n",
        "    except (ConnectionError, socket.timeout) as e:\n",
        "        print('ConnectionError or Timeout', link)\n",
        "        return 3, ''\n",
        "\n",
        "    try:\n",
        "        page = response.read()\n",
        "    except http.client.HTTPException as e:\n",
        "        print('HTTPException', link)\n",
        "        return 1, ''\n",
        "    except (ConnectionError, socket.timeout) as e:\n",
        "        print('ConnectionError or Timeout', link)\n",
        "        return 3, ''\n",
        "    return page"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLm2ou_qLW8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def callAll(page):\n",
        "  page = clean_page(page)\n",
        "  txt = parse_html(page)\n",
        "  txt = remove_non_alphanumeric(txt)\n",
        "  #txt = remove_non_alpha(txt)\n",
        "  txt = transliterate(txt)\n",
        "  txt = collapse_white_spaces(txt)\n",
        "  txt = connect_lines(txt)\n",
        "  return txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjHsNcV4boGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "link = 'https://job-openings.monster.ie/credit-risk-analyst-dublin-dublin-south-dublin-ie-adecco-retail/219418270'\n",
        "page = download_page(link)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1VDkUr529tO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "9908cb0d-4638-4d9a-a091-0460be66456a"
      },
      "source": [
        "callAll(page)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Credit Risk Analyst Dublin Description We are currently recruiting on behalf of our client for an Account Trading and Credit Analysis Lead. The successful candidate will be dealing directly with external clients be responsible for credit management and forecasting with previous manufacturing distributor commercial experience. Key Responsibilities Be a key point of contact for the customer and reseller base to ensure good flow of information for all stakeholders Be the owner of commercial detail oAnticipated revenues credit terms phasing and seasonality and work with insurers to secure requirements Have a good understanding the timing of specific deals is also essential Engaging directly with Resellers to confirm setups and gather additional information required Negotiating conditions of purchase or sale requesting gathering and interpreting financials building project Client interface to establish readiness to accept orders Reverting daily on queries to sales team Evaluate all available Financials. Weekly forecast business analysis report Order and payment status reporting Daily interactions with credit insurers Client reseller or credit insurer meeting notes and actions updated on a daily basis. Experience in the use of SAP is desirable and an advantage Knowledge Skills and Experience Previous experience with a manufacturer distributor commercial experience in consumer electronics or similar industry Higher level of education preferably in the area of commercial finance Business analytics and ability to interpret market data using Excel and web based systems Problem solving High level of communication skills and the ability to identify and influence key stakeholders If you are interested in this role and have the relevant skills and experience please apply for immediate consideration. Adecco Ireland is acting as an Employment Agency in relation to this vacancy. '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaQYq5GR3AOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}